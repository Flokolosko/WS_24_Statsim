---
title: "Exercise 3 -  Monte Carlo Simulation of areas"

output:
  pdf_document:
    toc: yes
    toc_depth: 4
    number_sections: yes
    latex_engine: xelatex
    df_print: paged
date: "2024-10-08"
author: Florian Stadler
---

```{r setup, include=FALSE,warning=FALSE}
knitr::opts_chunk$set(echo = TRUE,warning=FALSE,message=FALSE)
library(tinytex)
```

# Task 1 Monte Carlo Integration
In this task, we consider the integral
$$
\int_1^b{e^{-x^3}}.
$$
We will now compute following subtasks.

## Use uniformly distributed random variables to approximate the integral for b = 6 (using Monte Carlo integration). Then use the function integrate for comparison.

```{r}
f <- function(x){
  return (exp(-x**3))
}
monte.carlo.unif.based <- function(b, n){
  uniform.x <- runif(n,1,b)
  f.values <- f(uniform.x)
  average.f <- mean(f.values)
  int.est <- (b-1) * average.f
  return(int.est)
}

```
With the function monte.carlo.unif.based we can compute the monte carlo estimation for the given integral. Lets look at the values for  
n=100, b=6: Integral $\approx `r monte.carlo.unif.based(6,100)`$   
n=10000, b=6: Integral $\approx `r monte.carlo.unif.based(6,10000)`$  
n=1000000, b=6: Integral $\approx `r monte.carlo.unif.based(6,1000000)`$  
What the method does is to create a uniform sample in the integration area -> applies the function in the integral on all those data points -> takes the mean of the function values -> Multiply by the integral area. 
We can use the base r "integrate" function, to get the value of the integral.
for b=6 we get the Integral $= `r integrate(f,1,6)[[1]]`$ with an error of less than $3.2\cdot 10^{-7}$.
We observe that montecarlo comes pretty close when choosing high enough n. However, this also increases the computation time by a lot and for low n the difference is higher.


## Use Monte Carlo integration to compute the integral for b = ∞. What would be a good density for the simulation in that case? Use also the function integrate for comparison.
We cannot use the uniform distribution does not have the same support due to b = ∞. Therefore, we will use the exponential distribution and shift the integration levels. We get the equivalent integral
$$
\int_0^∞{e^{-(x+1)^3}}.
$$
we now have the same support as the exponential distribution and can compute the montecarlo integration with an exponential distrubuted sample.
```{r}
monte.carlo.exp.based <- function(n){
  x <- rexp(n)
  value <- mean(f(x+1)/dexp(x))
  return (value)
}
montecarlo.value<- monte.carlo.exp.based(1000000)
cat(paste("Monte Carlo Integral:",montecarlo.value))
integral.value <-integrate(f,1,Inf)[[1]]
cat(paste("True Integral:",integral.value))
cat(paste("The absolute difference of these methods is ",integral.value-montecarlo.value))
```
## Do you have an explanation why Monte Carlo integration agrees in 1.2 with integrate but not so much in 1.1?
By using the exponential distribution in 1.2, we naturally get more points that are closer to the range of arguments, where the integrand is bigger. The function in the integrand is larger, the closer the points are to 0.  Therefore, by choosing the exponential distribution, we did importance sampling. Thus we have reduced the variance of the estimate significantly since we have more data points at the "important" values. In 1.1, a lot more data points are at a value range, where the function is close to zero. Therefore, we need a much bigger sample size, to get more accurate results, when using uniform distribution for monte carlo estimation for this integral.

# Task 2 Multivariable Monte Carlo Approximation (2 Dimensional)
Monte Carlo simulation shall be utilized for obtaining the area enclosed by the graph of the function 
$$
r(t) = e^{\cos(t)} - 2\cdot \cos(4t) - \sin\left( \frac{t}{12}\right)^{5}, \text{for } t\in [-\pi,\pi],
$$
when using polar x- and y-coordinates
$$
x = r(t) \cos(t), y= r(t)\sin(t).
$$
## Visualization of the function
We will visualize the radius movement of r and the area of the function.
```{r,fig.show="hold", out.width="50%"}
r <- function(t) {
  return((exp(cos(t)) - 2 * cos(4*t) - sin(t/12)^5))
}
plot(r, -pi, pi, main="Radius movement", xlab="t", ylab="r(t)")

plot.butterfly<- function(main="Visualization of the Two-Dimensional Movement of the polar 
     function"){
  t <- seq(-pi, pi, length.out=2500)
x_coord <- r(t) * cos(t)
y_coord <- r(t) * sin(t)
plot(x_coord, y_coord, type="l", main=main, xlab="x", ylab="y",asp=.75)

polygon(x_coord, y_coord, col = rgb(0.20, 0.53, .52, alpha = 0.5))
}
plot.butterfly()
```
The area of the function looks like a bit like a butterfly :) (Although I think the head part should be inverted, but the R output and the PDF Output differ in the area coloring a bit. I couldn't figure out why)

## Generate uniform random coordinates within the rectangle [−2,3.5]×[−3,3] and an indicator whether this point lies within the area in question.

We will define a function, to decide, whether a function is inside the butterfly. Furthermore, with this function, we will indicate, whether a point is inside the butterfly and plot accordingly. For this, we will use the arcus tangens functions for 2 dimension. We furthermore plot 100, 1k, 10k and 100k random Points inside the butterfly.
Funfact: When I tried to set a seed before runif, I get a straight line of points, which may indicates that runif may be kind of cyclic. Therefore I did not set a seed before the runif functions. For verification we test the function for the point (0,0)

```{r,fig.show="hold", out.width="50%"}
library("tidyverse")

inside.butterfly <- function (x,y){
  z <- x^2 + y^2
  return (z<= r(atan2(y,x))^2)
}

cat("The point (0,0) is inside the function: ", inside.butterfly(0,0))

generate.points.butterfly <- function(n){
  x.coords <- runif(n,-2,3.5)
  y.coords <- runif(n,-3,3)
  df <- data.frame(x=x.coords,y=y.coords) %>% mutate(is.inside = inside.butterfly(x,y))
  title<- paste0(n," Points in the butterfly")
  plot.butterfly(title)
  points(df$x,df$y,col=ifelse(df$is.inside,"green","darkred"),pch=19,cex=.46)
  legend("topright",legend=c("Inside","Outside"), col = c("green","darkred"),pch=c(19,19))
  }

generate.points.butterfly(100)
generate.points.butterfly(1000)
```



```{r,fig.show="hold", out.width="50%"}
generate.points.butterfly(10000)
generate.points.butterfly(100000)
```

One can see, the more random points we plot and indicate them, the closer we get to the real figure. If we continue this for a large number of points, we expect to get the full are of the butterfly. Hence, montecarlo approximation is very useful for complex figures, where Integrating is very costly or difficult. To get the area estimate, we simply need to follow 2 steps. First, generate random points in the given intervalls and calculate the area of the rectangle of these intervalls. Secondly, we need to get the percentage of how many of those randomly generated points are in the desired area and then multiply with the area of the rectangle. For infinitely many points this converges to the integral of the said function. The most "complex" step in this algorithm is to get the algorithm, whether a point is inside the function area.  We get following table by doing so:

```{r,fig.show="hold", out.width="50%"}
get.inside.percentage <- function(n) {
  x.coords <- runif(n,-2,3.5)
  y.coords <- runif(n,-3,3)
  df <- data.frame(x=x.coords,y=y.coords) %>% mutate(is.inside = inside.butterfly(x,y))
  
  return(df %>% filter(is.inside==FALSE) %>% nrow()/ nrow(df))
}
area <- 5.5*6
last.table <- data.frame(n=c(100,1000,10000,100000),percentage=c(get.inside.percentage(100),get.inside.percentage(1000),get.inside.percentage(10000),get.inside.percentage(100000)))
last.table<- last.table %>% mutate(area=area*percentage)
knitr::kable(last.table)
```